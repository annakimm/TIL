{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "school_cell_uuid": "d441e6471a74402db2d83a976a414681"
   },
   "source": [
    "# 회귀 분석의 기하학"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "school_cell_uuid": "cd30599306134ee5b47b345b7fd63748"
   },
   "source": [
    "## 회귀 벡터 공간"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "school_cell_uuid": "f3309878652a491eb4cb966a341031a1"
   },
   "source": [
    "선형 회귀 분석으로 예측한 값 $\\hat{y}$는 $Xw$의 형태로 나타난다. 이를 살펴보면 $X$의 각 열 $c_1, \\cdots, c_M$을 기저 벡터(basis vector)로 하는 벡터 공간(vector space)위에 $\\hat{y}$가 있다는 것을 알 수 있다.\n",
    "\n",
    "$$ \n",
    "\\begin{eqnarray}\n",
    "\\hat{y} \n",
    "&=& Xw \\\\\n",
    "&=& \\begin{bmatrix} c_1 & \\cdots & c_M \\end{bmatrix} \\begin{bmatrix} w_1 \\\\ \\vdots \\\\ w_M \\end{bmatrix} \\\\\n",
    "&=& w_1 c_1 + \\cdots + w_M c_M \n",
    "\\end{eqnarray}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "school_cell_uuid": "097cc5a0132347afae41f258995fff18"
   },
   "source": [
    "<img src=\"https://datascienceschool.net/upfiles/99a909b0d8c74b1297ed2f97ed5aee0d.png\">\n",
    "여기에서 x1, x2가 c1, c2를 나타냄 c1w1, c2w2를 기저벡터로 하는 평면 상에 yhat이 있다. 100차원 공간상에 있는 평면이 생긴다. yhat은 이 평면상에 존재해야 한다. 하지만 실제 데이터는 이 평면상에 존재한다는 확신은 없다. 그래서 yhat을 최대한 y와 가깝게 계산해야 하고 그 거리는 y가 그 평면에 수직으로 내려와야 최단거리가 된다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "school_cell_uuid": "6f1c139213814fc289da2d0e36fee703"
   },
   "source": [
    "## 잔차 행렬과 프로젝션 행렬"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "school_cell_uuid": "6206da5065ea46068cbea58ecd3d0797"
   },
   "source": [
    "위 그림에서 보듯이 회귀 분석을 하면 그 결과로 $y$ 벡터를 예측값 벡터 $\\hat{y}$와 잔차 벡터 $e$로 분리하는 것을 알 수 있다. 이 때 예측값 벡터 $\\hat{y}$는 벡터 공간에 있고 잔차 벡터는 그 벡터 공간과 수직이므로 각각 프로젝션(projection) 및 리젝션(reject) 벡터를 구한 것이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "school_cell_uuid": "dbce0620a65649c78230e1b067c0921f"
   },
   "source": [
    "벡터에서 다른 벡터를 구하는 과정은 변형 행렬(transforma matrix)를 곱하는 연산으로 나타낼 수 있다. 그러면 $y$ 벡터를 잔차 벡터 $e$로 변형하는 잔차 행렬(residual matrix) $M$과 $y$ 벡터를 예측값 벡터 $\\hat{y}$로 변형하는 프로젝션 행렬(projection matrix) $P$를 각각 구해보자."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "school_cell_uuid": "5ce6d1e51c7d4283b930c9181ce16aa4"
   },
   "source": [
    "$$ e = My $$\n",
    "\n",
    "$$ \\hat{y} = Py $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "school_cell_uuid": "3b5d5a6ec63a45bfadc11f8a2023d270"
   },
   "source": [
    "$$\n",
    "\\begin{eqnarray}\n",
    "e \n",
    "&=& y - Xw \\\\\n",
    "&=& y - X(X^TX)^{-1}X^Ty \\\\\n",
    "&=& (I - X(X^TX)^{-1}X^T)y \\\\\n",
    "&=& My \\\\\n",
    "\\end{eqnarray}\n",
    "$$\n",
    "\n",
    "$$ \\hat{y} = y - e = X(X^TX)^{-1}X^T y $$\n",
    "\n",
    "따라서 $M$, $P$는 각각 다음과 같다.\n",
    "\n",
    "$$ P = X(X^TX)^{-1}X^T $$\n",
    "\n",
    "$$ M = I - X(X^TX)^{-1}X^T = I - P $$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "school_cell_uuid": "c52dc24f931a44f79bb5d8dc95e233f3"
   },
   "source": [
    "잔차 행렬과 프로젝션 행렬은 다음과 같은 성질이 있다.\n",
    "\n",
    "(1) 대칭 행렬이다.\n",
    "\n",
    "$$ M^T = M $$\n",
    "\n",
    "$$ P^T = P $$\n",
    "\n",
    "(2) 곱해도 자기 자신이 되는 행렬이다. $N$제곱을 해도 자기 자신이 된다.\n",
    "\n",
    "$$ M^2 = M $$\n",
    "\n",
    "$$ P^2 = P $$\n",
    "\n",
    "(3) $X$와 직교한다.\n",
    "\n",
    "$$ PX = MX = 0 $$\n",
    "\n",
    "(4) $M$과 $P$가 서로 직교한다.\n",
    "\n",
    "$$ MP = PM = 0 $$\n",
    "\n",
    "(5) 합이 단위 행렬이다.\n",
    "\n",
    "$$ M + P = I $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "school_cell_uuid": "db0c557f74254c02b406333b308c479f"
   },
   "source": [
    "이 행렬을 이용하면 회귀 분석의 예측값을 다음처럼 표현할 수 있다.\n",
    "\n",
    "$$ y = \\hat{y} + e = Py + My = (P + M)y $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "school_cell_uuid": "bddf9a4b6e7e4978835f7a20ab023fa0"
   },
   "source": [
    "아래에 위 성질의 일부를 증명하였다. 나머지도 같은 방법으로 증명할 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "school_cell_uuid": "2dcf020cf0e14cafb251f8e48e8d8544"
   },
   "source": [
    "$$\n",
    "\\begin{eqnarray}\n",
    "M^T \n",
    "&=& (I - X(X^TX)^{-1}X^T)^T \\\\\n",
    "&=& I - (X(X^TX)^{-T}X)^T \\\\\n",
    "&=& I - X((X^TX)^T)^{-1}X^T \\\\\n",
    "&=& I - X(X^TX)^{-1}X^T \\\\\n",
    "&=& M\n",
    "\\end{eqnarray}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "school_cell_uuid": "186097c22b5f4be09c2613e2d464fdbe"
   },
   "source": [
    "$$\n",
    "\\begin{eqnarray}\n",
    "M^2 \n",
    "&=& (I - X(X^TX)^{-1}X^T)(I - X(X^TX)^{-1}X^T) \\\\\n",
    "&=& I - 2X(X^TX)^{-T}X^T + X(X^TX)^{-1}X^TX(X^TX)^{-1}X^T\\\\\n",
    "&=& I - X((X^TX)^T)^{-1}X^T \\\\\n",
    "&=& M\n",
    "\\end{eqnarray}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "school_cell_uuid": "d77f9c9d55164c25b9828ecd43c364fb"
   },
   "source": [
    "$$\n",
    "\\begin{eqnarray}\n",
    "MX\n",
    "&=& (I - X(X^TX)^{-1}X^T)X \\\\\n",
    "&=& X - X(X^TX)^{-1}X^TX \\\\\n",
    "&=& X - X\\\\\n",
    "&=& 0\n",
    "\\end{eqnarray}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "school_cell_uuid": "3c67650326974bcf9334dd0db333a62a"
   },
   "source": [
    "$$\n",
    "\\begin{eqnarray}\n",
    "MP \n",
    "&=& (I - X(X^TX)^{-1}X^T)X(X^TX)^{-1}X^T \\\\\n",
    "&=& X(X^TX)^{-T}X^T - X(X^TX)^{-1}X^TX(X^TX)^{-1}X^T\\\\\n",
    "&=& X(X^TX)^{-T}X^T - X(X^TX)^{-1}X^T\\\\\n",
    "&=& 0\n",
    "\\end{eqnarray}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "school_cell_uuid": "6ce5db3b612b45e7835620de8344a2a6"
   },
   "source": [
    "위 성질을 이용하면 $y$, $e$, $\\hat{y}$ 벡터의 제곱합 사이에 다음과 같은 관계가 있음을 증명할 수 있다.(피타고라스 정리는 $N$차원에서도 성립한다.)\n",
    "\n",
    "$$\n",
    "\\begin{eqnarray}\n",
    "y^Ty \n",
    "&=& ((P + M)y)^T((P + M)y) \\\\\n",
    "&=& y^T (P + M)^T (P + M)y \\\\\n",
    "&=& y^T (P + M) y \\\\\n",
    "&=& y^T P y + y^T M y \\\\\n",
    "&=& y^T P^T P y + y^T M^T M y \\\\\n",
    "&=& (Py)^T (Py) + (My)^T (My) \\\\\n",
    "&=& \\hat{y}^T \\hat{y} + e^T e \\\\\n",
    "\\end{eqnarray}\n",
    "$$\n",
    "\n",
    "이 관계식은 추후 분산 분석(ANOVA)에 사용된다."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
